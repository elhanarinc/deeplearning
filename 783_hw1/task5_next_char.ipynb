{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Regression (predict next character in a word) exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [HW page](http://kovan.ceng.metu.edu.tr/~sinan/DL/index.html) on the course website.*\n",
    "\n",
    "Having gained some experience with neural networks, let us train a network that predicts the next character given a set of characters in a text.\n",
    "\n",
    "All of your work for this exercise will be done in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from metu.data_utils import load_nextchar_dataset, plain_text_file_to_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a small net and some toy data to check your implementations.\n",
    "# Note that we set the random seed for repeatable experiments.\n",
    "from cs231n.classifiers.neural_net_for_regression import TwoLayerNet\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "  np.random.seed(0)\n",
    "  return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "  np.random.seed(1)\n",
    "  X = 10 * np.random.randn(num_inputs, input_size)\n",
    "  y = np.array([[0, 1, 2], [1, 2, 3], [2, 3, 4], [2, 1, 4], [2, 1, 4]])\n",
    "  return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute scores\n",
    "Open the file `cs231n/classifiers/neural_net_for_regression.py` and look at the method `TwoLayerNet.loss`. This function is very similar to the loss functions you have written for the previous exercises: It takes the data and weights and computes the *regression* scores, the squared error loss, and the gradients on the parameters. \n",
    "\n",
    "To be more specific, you will implement the following loss function:\n",
    "\n",
    "$$\\frac{1}{2}\\sum_i (o_i - y_i)^2 + \\frac{1}{2}\\lambda\\sum_j w_j^2,$$\n",
    "\n",
    "where $i$ runs through the samples in the batch; $o_i$ is the prediction of the network for the $i^{th}$ sample, and $y_i$ is the correct character; $\\lambda$ is the weight of the regularization term.\n",
    "\n",
    "The first layer uses ReLU as the activation function. The output layer does not use any activation functions.\n",
    "\n",
    "Implement the first part of the forward pass which uses the weights and biases to compute the scores for all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "correct scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "Difference between your scores and correct scores:\n",
      "3.68027209255e-08\n"
     ]
    }
   ],
   "source": [
    "scores = net.loss(X)\n",
    "print 'Your scores:'\n",
    "print scores\n",
    "print\n",
    "print 'correct scores:'\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print correct_scores\n",
    "print\n",
    "\n",
    "# The difference should be very small. We get < 1e-7\n",
    "print 'Difference between your scores and correct scores:'\n",
    "print np.sum(np.abs(scores - correct_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute loss\n",
    "In the same function, implement the second part that computes the data and regularizaion loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between your loss and correct loss:\n",
      "2.54800625044e-11\n"
     ]
    }
   ],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.1)\n",
    "correct_loss = 66.3406756909\n",
    "\n",
    "# should be very small, we get < 1e-10\n",
    "print 'Difference between your loss and correct loss:'\n",
    "print np.sum(np.abs(loss - correct_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass\n",
    "Implement the rest of the function. This will compute the gradient of the loss with respect to the variables `W1`, `b1`, `W2`, and `b2`. Now that you (hopefully!) have a correctly implemented forward pass, you can debug your backward pass using a numeric gradient check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2 max relative error: 1.443387e-06\n",
      "W2 max relative error: 3.755046e-04\n",
      "W1 max relative error: 5.463838e-04\n",
      "b1 max relative error: 2.188996e-07\n"
     ]
    }
   ],
   "source": [
    "from cs231n.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Use numeric gradient checking to check your implementation of the backward pass.\n",
    "# If your implementation is correct, the difference between the numeric and\n",
    "# analytic gradients should be less than 1e-8 for each of W1, W2, b1, and b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.1)\n",
    "\n",
    "# these should all be less than 1e-8 or so\n",
    "for param_name in grads:\n",
    "  f = lambda W: net.loss(X, y, reg=0.1)[0]\n",
    "  param_grad_num = eval_numerical_gradient(f, net.params[param_name])\n",
    "  print '%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a dataset for training a simple regression network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting plain text file to trainable dataset (as pickle file)\n",
      "Processing file metu/dataset/shakespeare.txt as input\n",
      "input_size parameter (i.e. num of neurons) will be 5\n",
      "Writing data and labels to file metu/dataset/nextchar_data.pkl\n",
      "Loading X and Y from pickle file metu/dataset/nextchar_data.pkl\n",
      "Number of instances in the training set:  37647\n",
      "Number of instances in the validation set:  3764\n",
      "Number of instances in the testing set:  22589\n"
     ]
    }
   ],
   "source": [
    "# Load the TEXT data\n",
    "# If your memory turns out to be sufficient, try the following:\n",
    "#def get_nextchar_data(training_ratio=0.6, val_ratio=0.1):\n",
    "def get_nextchar_data(training_ratio=0.1, test_ratio=0.06, val_ratio=0.01):\n",
    "  # Load the nextchar training data \n",
    "  X, y = load_nextchar_dataset(nextchar_datafile)\n",
    "  # Subsample the data\n",
    "  length=len(y)\n",
    "  num_training=int(length*training_ratio)\n",
    "  num_val = int(length*val_ratio)\n",
    "  num_test = min((length-num_training-num_val), int(length*test_ratio))\n",
    "  mask = range(num_training-1)\n",
    "  X_train = X[mask]\n",
    "  y_train = y[mask]\n",
    "  mask = range(num_training, num_training+num_test)\n",
    "  X_test = X[mask]\n",
    "  y_test = y[mask]\n",
    "  mask = range(num_training+num_test, num_training+num_test+num_val)\n",
    "  X_val = X[mask]\n",
    "  y_val = y[mask]\n",
    "\n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "nextchar_datafile = 'metu/dataset/nextchar_data.pkl'\n",
    "input_size = 5 # Size of the input of the network\n",
    "#plain_text_file_to_dataset(\"metu/dataset/ince_memed_1.txt\", nextchar_datafile, input_size)\n",
    "plain_text_file_to_dataset(\"metu/dataset/shakespeare.txt\", nextchar_datafile, input_size)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_nextchar_data()\n",
    "print \"Number of instances in the training set: \", len(X_train)\n",
    "print \"Number of instances in the validation set: \", len(X_val)\n",
    "print \"Number of instances in the testing set: \", len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input - Next char to be predicted\n",
      "HE SO - N\n",
      "E SON - N\n",
      " SONN - E\n",
      "SONNE - T\n",
      "ONNET - S\n",
      "by Wi - l\n",
      "y Wil - l\n",
      " Will - i\n",
      "Willi - a\n"
     ]
    }
   ],
   "source": [
    "# We have loaded the dataset. That wasn't difficult, was it? :)\n",
    "# Let's look at a few samples\n",
    "#\n",
    "from metu.data_utils import int_list_to_string, int_to_charstr\n",
    "\n",
    "print \"Input - Next char to be predicted\"\n",
    "for i in range(1,10):\n",
    "    print int_list_to_string(X_train[i]) + \" - \" + int_list_to_string(y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now train our network on the nextchar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 5000: loss 872054.217734\n",
      "iteration 100 / 5000: loss 44589987.703858\n",
      "iteration 200 / 5000: loss 173103615.237301\n",
      "iteration 300 / 5000: loss 180175544.581196\n",
      "iteration 400 / 5000: loss 186118204.289275\n",
      "iteration 500 / 5000: loss 187667823.142380\n",
      "iteration 600 / 5000: loss 195029910.734469\n",
      "iteration 700 / 5000: loss 194713617.823324\n",
      "iteration 800 / 5000: loss 196538390.314120\n",
      "iteration 900 / 5000: loss 196261953.899351\n",
      "iteration 1000 / 5000: loss 196602899.600939\n",
      "iteration 1100 / 5000: loss 196444501.238045\n",
      "iteration 1200 / 5000: loss 196332107.893332\n",
      "iteration 1300 / 5000: loss 196159884.262371\n",
      "iteration 1400 / 5000: loss 196098685.555416\n",
      "iteration 1500 / 5000: loss 195914069.271241\n",
      "iteration 1600 / 5000: loss 195832414.172776\n",
      "iteration 1700 / 5000: loss 195698415.153902\n",
      "iteration 1800 / 5000: loss 195610404.587115\n",
      "iteration 1900 / 5000: loss 195539740.403808\n",
      "iteration 2000 / 5000: loss 195463925.031710\n",
      "iteration 2100 / 5000: loss 195392642.807388\n",
      "iteration 2200 / 5000: loss 195328438.134628\n",
      "iteration 2300 / 5000: loss 195262321.526485\n",
      "iteration 2400 / 5000: loss 195205023.729235\n",
      "iteration 2500 / 5000: loss 195133637.091612\n",
      "iteration 2600 / 5000: loss 195080136.880384\n",
      "iteration 2700 / 5000: loss 195015222.596689\n",
      "iteration 2800 / 5000: loss 194962339.572944\n",
      "iteration 2900 / 5000: loss 194922327.362130\n",
      "iteration 3000 / 5000: loss 194862194.872448\n",
      "iteration 3100 / 5000: loss 194826876.551442\n",
      "iteration 3200 / 5000: loss 194772252.526859\n",
      "iteration 3300 / 5000: loss 194734610.321586\n",
      "iteration 3400 / 5000: loss 194688735.479426\n",
      "iteration 3500 / 5000: loss 194655166.829138\n",
      "iteration 3600 / 5000: loss 194614284.093275\n",
      "iteration 3700 / 5000: loss 194565358.634759\n",
      "iteration 3800 / 5000: loss 194530739.031144\n",
      "iteration 3900 / 5000: loss 194496200.483283\n",
      "iteration 4000 / 5000: loss 194468436.135455\n",
      "iteration 4100 / 5000: loss 194432942.014319\n",
      "iteration 4200 / 5000: loss 194399885.084828\n",
      "iteration 4300 / 5000: loss 194369029.210734\n",
      "iteration 4400 / 5000: loss 194335402.617998\n",
      "iteration 4500 / 5000: loss 194305163.403082\n",
      "iteration 4600 / 5000: loss 194277406.874918\n",
      "iteration 4700 / 5000: loss 194246311.578301\n",
      "iteration 4800 / 5000: loss 194220653.916028\n",
      "iteration 4900 / 5000: loss 194198094.413120\n",
      "Validation error:  31773459.0\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train a neural network\n",
    "\n",
    "input_size = input_size\n",
    "hidden_size = 10000\n",
    "num_classes = 1\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Train the network\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=5000, batch_size=32,\n",
    "            learning_rate=1e-5, learning_rate_decay=0.95,\n",
    "            reg=0.5, verbose=True)\n",
    "\n",
    "# Predict on the validation set\n",
    "val_err = np.sum(np.square(net.predict(X_val) - y_val), axis=1).mean()\n",
    "print 'Validation error: ', val_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug the training\n",
    "I have managed to get a loss below 10,000 and a validation error of about 1100 on the validation set (by playing around the parameters a little bit). However, this isn't very good.\n",
    "\n",
    "One strategy for getting insight into what's wrong is to plot the loss function and the accuracies on the training and validation sets during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoEAAAHwCAYAAADZxbVBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOogkEAAAoINIAgEAADqIJBAAAKCD/h9m2lmeShR+EQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc511557c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss function and train / validation errors\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "train = plt.plot(stats['train_err_history'], label='train')\n",
    "val = plt.plot(stats['val_err_history'], label='val')\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.title('Classification error history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input - predicted char - true char\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6697b3ec0231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Input - predicted char - true char\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mint_list_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" - \"\u001b[0m          \u001b[0;34m+\u001b[0m \u001b[0mint_list_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;34m+\u001b[0m \u001b[0;34m\" - \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint_list_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/leoric/Desktop/deeplearning/783_hw1/cs231n/classifiers/neural_net_for_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# TODO: Implement this function; it should be VERY simple!                #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m###########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;31m###########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;31m#                              END OF YOUR CODE                           #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leoric/Desktop/deeplearning/783_hw1/cs231n/classifiers/neural_net_for_regression.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, X, y, reg)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Compute the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "# Show some sample outputs:\n",
    "\n",
    "print \"Input - predicted char - true char\"\n",
    "for i in range(1,10):\n",
    "    print int_list_to_string(X_val[i]) + \" - \"  \\\n",
    "        + int_list_to_string([int(x) for x in net.predict(X_val[i])]) \\\n",
    "        + \" - \" + int_list_to_string(y_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
